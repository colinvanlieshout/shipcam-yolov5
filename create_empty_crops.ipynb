{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random_cropping\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import random\n",
    "from math import floor, ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_crop_size = 1024\n",
    "\n",
    "DATA_PATH = \"C:/Users/clieshou/Documents/Sogeti/The Ocean Cleanup/Plasticdebris_data/\"\n",
    "image_paths = glob.glob(DATA_PATH + 'images/shipcam/*')\n",
    "OUTPUT_PATH = \"shipcam_emptycrops/images\"\n",
    "label_file_name = \"labels_split.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_PATH, label_file_name), delimiter=';')\n",
    "df['filename'] = df['filename'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_center_sampling_region(image_width, image_height,desired_crop_size):\n",
    "    \"\"\"\n",
    "    Steps:\n",
    "    Determines from what region the center of the crop can be randomly selected.\n",
    "    It does this by compensating desired crop size for the size of the bounding box, to avoid it not being fully included.\n",
    "    It compensates for the fact that bounding boxes may be close to the edge of the image, didn't get to it yet\n",
    "    \"\"\"\n",
    "\n",
    "    #we want to select the center of the crop randomly, but have to make sure that the entire bb falls within the crop\n",
    "    center_sampling_region_xmin = desired_crop_size/2 \n",
    "    center_sampling_region_ymin = desired_crop_size/2 \n",
    "    center_sampling_region_xmax = image_width - desired_crop_size/2 \n",
    "    center_sampling_region_ymax = image_height - desired_crop_size/2 \n",
    "\n",
    "    #randomly getting the center within the allowed frame, using seed to get the same each time for the same bounding box. Not sure if there are any reasons not to do this\n",
    "    # random.seed()\n",
    "    crop_xcenter = random.randint(floor(center_sampling_region_xmin), ceil(center_sampling_region_xmax))\n",
    "    # random.seed(bb_ymin)\n",
    "    crop_ycenter = random.randint(floor(center_sampling_region_ymin), ceil(center_sampling_region_ymax))\n",
    "\n",
    "    #make sure the center fall within the acceptable frame, where the entire crop will fall within the image\n",
    "    if crop_xcenter < desired_crop_size/2:\n",
    "        crop_xcenter = desired_crop_size/2\n",
    "    if crop_xcenter > (image_width - desired_crop_size/2):\n",
    "        crop_xcenter = (image_width - desired_crop_size/2)\n",
    "    if crop_ycenter < desired_crop_size/2:\n",
    "        crop_ycenter = desired_crop_size/2\n",
    "    if crop_ycenter > (image_height - desired_crop_size/2):\n",
    "        crop_ycenter = (image_height - desired_crop_size/2)\n",
    "\n",
    "    return crop_xcenter, crop_ycenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_crop_per_bb(image_path, df_image, desired_crop_size):\n",
    "    \"\"\"\n",
    "    This functions aim is to obtain crops of a specified size from images of any size. \n",
    "    It does this by first checking whether the bounding box of interest is larger or smaller than desired.\n",
    "    If larger, it downsamples the entire image first.\n",
    "    Then, we determine from what region the center of the crop can be sampled such that the bb will always fully fall within the image.\n",
    "\n",
    "    input:\n",
    "    - i: index of the object of interest for the current image\n",
    "    - image: the path to the image\n",
    "    - df_image: subset of the total df, only contains rows of this image\n",
    "    - downsample_marging: how much smaller should the bounding box be than the image, 1 is the same, 2 is half\n",
    "    \n",
    "    returns:\n",
    "    - crop: cropped image\n",
    "    - crop_coordinates: xmin, ymin, xmax and ymax of the crop within the original image\n",
    "    \"\"\"\n",
    "\n",
    "    image_to_crop = Image.open(image_path)\n",
    "    #initialize variables for the required data\n",
    "    # bb_data = df_image.iloc[i, :]\n",
    "    # bb_xmin, bb_ymin, bb_xmax, bb_ymax = bb_data['xmin'], bb_data['ymin'], bb_data['xmax'], bb_data['ymax']\n",
    "    \n",
    "    #check if a bounding box is too large for the desired crop size, and if so, sample it down\n",
    "    \n",
    "    #determine what the center of the crop should be\n",
    "    image_width, image_height = image_to_crop.size\n",
    "    center_sampling_region_xcenter, center_sampling_region_ycenter = define_center_sampling_region(image_width, image_height, desired_crop_size)\n",
    "\n",
    "    #determine crop coordinates, then crop\n",
    "    crop_xmin = center_sampling_region_xcenter - desired_crop_size/2\n",
    "    crop_ymin = center_sampling_region_ycenter - desired_crop_size/2\n",
    "    crop_xmax = center_sampling_region_xcenter + desired_crop_size/2\n",
    "    crop_ymax = center_sampling_region_ycenter + desired_crop_size/2\n",
    "\n",
    "    crop_coordinates = (crop_xmin, crop_ymin, crop_xmax, crop_ymax)\n",
    "    crop = image_to_crop.crop(crop_coordinates)\n",
    "\n",
    "    return crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_crop_size = 1024\n",
    "df_image = df[df['filename'] == image_path.split(\"/\")[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "shipcam_emptycrops/images\\dsc00968_crop.jpg\n",
      "shipcam_emptycrops/images\\dsc00968_crop.jpg\n",
      "shipcam_emptycrops/images\\dsc00968_crop.jpg\n",
      "shipcam_emptycrops/images\\dsc00968_crop.jpg\n",
      "shipcam_emptycrops/images\\dsc00968_crop.jpg\n",
      "shipcam_emptycrops/images\\dsc00968_crop.jpg\n",
      "shipcam_emptycrops/images\\dsc00968_crop.jpg\n",
      "shipcam_emptycrops/images\\dsc00968_crop.jpg\n",
      "shipcam_emptycrops/images\\dsc00968_crop.jpg\n",
      "shipcam_emptycrops/images\\dsc00968_crop.jpg\n",
      "shipcam_emptycrops/images\\dsc00968_crop.jpg\n",
      "shipcam_emptycrops/images\\dsc00968_crop.jpg\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-a913ac4dbc24>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mimage_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\\\\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mcrop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_crop_per_bb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesired_crop_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mdf_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'filename'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-65-aa8202cf135a>\u001b[0m in \u001b[0;36mgenerate_crop_per_bb\u001b[1;34m(image_path, df_image, desired_crop_size)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mcrop_coordinates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcrop_xmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcrop_ymin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcrop_xmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcrop_ymax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0mcrop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage_to_crop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcrop_coordinates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcrop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\yolov5-shipcam\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mcrop\u001b[1;34m(self, box)\u001b[0m\n\u001b[0;32m   1125\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1127\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1128\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_crop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\yolov5-shipcam\\lib\\site-packages\\PIL\\ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m                             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m                             \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m                                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "crops_created = 0\n",
    "while crops_created < 1000:\n",
    "    \n",
    "    random_select = random.randint(0, len(image_paths))\n",
    "    image_path = image_paths[random_select]\n",
    "    image_name = image_path.split(\"/\")[-1].split(\"\\\\\")[1]\n",
    "\n",
    "    crop = generate_crop_per_bb(image_path, df_image, desired_crop_size)\n",
    "\n",
    "    df_image = df[df['filename'] == image_name]\n",
    "\n",
    "    image_path_crop = os.path.join(OUTPUT_PATH, image_name.split('.')[0] + '_crop.jpg')\n",
    "\n",
    "    print(image_path_crop)\n",
    "    crop.save(image_path_crop)\n",
    "\n",
    "    crops_created += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = image_paths[0]"
   ]
  }
 ]
}